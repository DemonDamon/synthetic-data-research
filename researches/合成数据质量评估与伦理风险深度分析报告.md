# 合成数据质量评估与伦理风险深度分析报告


## 1. 摘要

本报告对合成数据的质量评估方法和伦理风险进行了深入分析，特别是关注数据偏见的继承与放大问题。在质量评估方面，报告详细阐述了衡量合成数据保真度、多样性和实用性的关键指标，包括统计比较、Hellinger距离、PCD、DD-Plot R²、AUC-ROC、DCScore、TSTR/TRTR框架及QScore等。在伦理风险方面，报告剖析了生成模型如何学习并放大训练数据中已有的社会偏见，探讨了数据完整性、混淆风险及隐私泄露等问题，并概述了在合成数据领域减轻或消除偏见的算法公平性策略，例如预训练、训练、后训练干预和技术解决方案。

## 2. 背景与介绍

随着人工智能和数据驱动决策的快速发展，合成数据已成为解决真实数据稀缺、隐私保护和合规性挑战的重要工具。合成数据是算法生成的数据，旨在模拟原始数据的统计特性和模式，同时不包含真实的个人敏感信息。尽管其潜力巨大，但合成数据的有效应用依赖于对其质量的精确评估以及对其内在伦理风险的深刻理解。本报告旨在从“质量评估方法”和“伦理风险（如偏见放大）”两大核心方面，构建对合成数据进行扩展性研究的深度分析，为合成数据在各领域的负责任应用提供理论基础和实践指导。

## 3. 核心发现

### 3.1 质量评估方法

合成数据质量的评估是确保其可靠性和可用性的基石。评估主要围绕以下三个核心维度展开：保真度、多样性和实用性。

#### 3.1.1 保真度 (Fidelity)

保真度衡量合成数据与真实数据在统计分布和结构上有多接近。高保真度意味着合成数据能够准确反映原始数据的特性。主要的评估指标和方法包括：

*   **探索性统计比较:** 通过比较原始数据集与合成数据集的均值、中位数、标准差、独特值、缺失值、最小值、最大值、四分位距（针对连续特征）以及每类记录数、每类缺失值等关键统计量，初步判断统计相似性。[[ref]](https://aws.amazon.com/blogs/machine-learning/how-to-evaluate-the-quality-of-the-synthetic-data-measuring-from-the-perspective-of-fidelity-utility-and-privacy/)
*   **直方图相似度分数:** 量化每个特征的边际分布在原始数据和合成数据之间的相似程度。分数范围介于0到1之间，1表示完美重叠。[[ref]](https://aws.amazon.com/blogs/machine-learning/how-to-evaluate-the-quality-of-the-synthetic-data-measuring-from-the-perspective-of-fidelity-utility-and-privacy/)
*   **互信息分数:** 评估两个特征之间的相互依赖性，包括非线性关系。分数越高表示原始数据中变量关系保留得越好，最高为1。[[ref]](https://aws.amazon.com/blogs/machine-learning/how-to-evaluate-the-quality-of-the-synthetic-data-measuring-from-the-perspective-of-fidelity-utility-and-privacy/)
*   **相关性分数:** 衡量原始数据中特征间的相关性在合成数据中保留的程度。分数介于0到1之间，1表示完美匹配。特别地，可以使用 ϕk 常数计算混合类型变量的相关矩阵。[[ref]](https://aws.amazon.com/blogs/machine-learning/how-to-evaluate-the-quality-of-the-synthetic-data-measuring-from-the-perspective-of-fidelity-utility-and-privacy/)[[ref]](https://www.frontiersin.org/journals/digital-health/articles/10.3389/fdgth.2025.1576290/full)
*   **Hellinger 距离:** 量化两个概率分布（真实与合成）的相似性，取值范围为0到1，0表示分布完全相同。该指标对数值和分类属性均具有鲁棒性，且对异常值不敏感。[[ref]](https://www.frontiersin.org/journals/digital-health/articles/10.3389/fdgth.2025.1576290/full)
*   **深度-深度图 (DD-Plot) 的决定系数 (R²):** 这是一种非参数方法，用于评估真实数据和合成数据之间的多变量分布相似性。R²值越接近1，表明合成样本来自与真实样本相同的多变量分布。[[ref]](https://www.frontiersin.org/journals/digital-health/articles/10.3389/fdgth.2025.1576290/full)
*   **受试者工作特征曲线下面积 (AUC-ROC):** 衡量分类器区分真实样本和合成样本的能力。AUC-ROC值越接近0.5，表示合成数据与真实数据越难以区分，即保真度越高。[[ref]](https://www.frontiersin.org/journals/digital-health/articles/10.3389/fdgth.2025.1576290/full)
*   **自相关和偏自相关分数:** 特别针对时间序列数据，评估合成数据是否有效捕获了原始数据的显著自相关或偏自相关关系。[[ref]](https://aws.amazon.com/blogs/machine-learning/how-to-evaluate-the-quality-of-the-synthetic-data-measuring-from-the-perspective-of-fidelity-utility-and-privacy/)

#### 3.1.2 多样性 (Diversity)

多样性评估生成数据是否充分覆盖了真实数据的全部分布模式，而不仅仅是重复少数“众数”模式。这是确保合成数据能够代表现实世界复杂性的关键。目前的评估方法包括：

*   **DCScore:** 一种基于分类视角的合成数据集多样性评估方法。其核心思想是将多样性评估视为一个样本分类任务，通过捕捉样本间的相互关系来衡量。DCScore的计算涉及文本表示、成对相似度计算（生成核矩阵K）和多样性汇总（通过核矩阵计算分类概率矩阵P的迹）。高DCScore值表明样本的丰富性高。[[ref]](https://arxiv.org/html/2502.08512v1)
    *   **DCScore满足的公理:** 包括有效数量（多样性是数据集中有效样本的数量，范围从1到n）、相同样本（合并相同数据集多样性不变）、对称性（多样性与样本顺序无关）和单调性（样本相似性增加，多样性减少）。[[ref]](https://arxiv.org/html/2502.08512v1)
*   **其他基于N-gram、参考或转换的方法:** 传统NLP和ML领域的多样性评估方法，如Distinct-n（关注词汇形式差异）、Reference-based方法（通过参考分布或数据近似人类判断）和Transformation-based方法（将数据映射到表示空间后进行多样性汇总，但可能计算成本较高）。[[ref]](https://arxiv.org/html/2502.08512v1)

#### 3.1.3 实用性 (Utility)

实用性衡量合成数据在下游任务中的性能表现，即使用合成数据训练的模型与使用真实数据训练的模型在性能上的差异。关键指标包括：

*   **预测分数 (Prediction Score):** 在合成数据上训练机器学习模型，然后在原始数据的保留测试集上进行评估。通过比较 TSTR (Train Synthetic Test Real) 和 TRTR (Train Real Test Real) 分数来衡量，若两者接近，则表明合成数据对训练ML模型具有足够效用。此方法适用于分类和回归任务，并使用多种ML算法进行验证。[[ref]](https://aws.amazon.com/blogs/machine-learning/how-to-evaluate-the-quality-of-the-synthetic-data-measuring-from-the-perspective-of-fidelity-utility-and-privacy/)
*   **特征重要性分数 (Feature Importance Score):** 比较在合成数据和真实数据上训练模型所获得的特征重要性排序的稳定性。若排序保持一致，则表明合成数据具有高实用性。[[ref]](https://aws.amazon.com/blogs/machine-learning/how-to-evaluate-the-quality-of-the-synthetic-data-measuring-from-the-perspective-of-fidelity-utility-and-privacy/)
*   **QScore:** 通过对合成数据和原始数据执行多个随机的、基于聚合的查询来评估下游应用的性能。如果查询结果相似，则QScore较高，表示合成数据能为依赖查询和聚合操作的下游应用提供接近真实数据的价值。[[ref]](https://aws.amazon.com/blogs/machine-learning/how-to-evaluate-the-quality-of-the-synthetic-data-measuring-from-the-perspective-of-fidelity-utility-and-privacy/)
*   **保真度-实用性权衡 (Fidelity-Utility Tradeoff - G指标):** 这是一个单一的可解释值，旨在捕捉合成数据在保持实用性同时兼顾保真度的能力。它结合了PCD和TSTR-TRTR指标差异，适用于比较不同的生成模型或参数配置，尤其是在存在隐私约束（如差分隐私DP）时，通过 Gϵ 值量化权衡。较低的G值表示保真度与实用性之间的平衡更好。[[ref]](https://www.frontiersin.org/journals/digital-health/articles/10.3389/fdgth.2025.1576290/full)

### 3.2 伦理风险与偏见放大

合成数据虽然能解决诸多数据挑战，但在伦理层面也引入了新的风险，特别是数据偏见的继承与放大。

#### 3.2.1 偏见继承与放大 (Inheritance and Amplification of Bias)

*   **生成模型学习并放大社会偏见:** 生成式人工智能（GenAI）系统在训练过程中可能学习并放大训练数据中固有的社会偏见，例如性别、种族偏见。这可能导致AI系统不仅不准确，而且系统性地产生不公平结果。[[ref]](https://www.pnas.org/doi/10.1073/pnas.2409182122)[[ref]](https://pmc.ncbi.nlm.nih.gov/articles/PMC12778113/)[[ref]](https://www.adalovelaceinstitute.org/blog/synthetic-data-real-harm/)
*   **数据完整性问题:** GenAI合成数据可能被误报为真实数据，生成高度逼真的图像、医疗数据或临床试验数据，甚至被用于篡改真实数据以支持特定假设。这为研究不端行为（伪造、篡改数据）提供了土壤，严重威胁科学研究的完整性。[[ref]](https://www.pnas.org/doi/10.1073/pnas.2409182122)
*   **混淆风险:** 合成数据与真实数据之间的混淆可能损害研究记录，降低科学数据和分析方法的质量及可重复性，甚至可能适得其反地破坏AI模型的训练。例如，美国FDA对在药物审批中使用合成数据仍存公共健康风险的担忧。[[ref]](https://www.pnas.org/doi/10.1073/pnas.2409182122)
*   **隐私泄露风险:** 尽管合成数据的设计目标是保护隐私，但若生成过程缺乏强大的安全措施，或合成数据中包含能够重建原始隐私信息的特征，则仍可能导致机密性和隐私泄露。[[ref]](https://www.pnas.org/doi/10.1073/pnas.2409182122)

#### 3.2.2 算法公平性与缓解策略 (Algorithmic Fairness and Mitigation Strategies)

为应对合成数据中的伦理风险和偏见问题，研究人员提出了多种策略和技术，旨在促进算法公平性：

*   **偏见缓解的生命周期方法:** 偏见缓解策略可分为三个阶段：
    *   **预训练 (Pre-training) 阶段:** 在数据生成阶段就主动引入公平性。例如，通过创建平衡、多样化的训练数据集来消除歧视性偏见，或利用因果模型调整因果关系和概率来生成减轻偏见的数据集。[[ref]](https://www.sciencedirect.com/science/article/pii/S0167739X24000694)[[ref]](https://bluegen.ai/how-does-synthetic-data-generation-help-reduce-algorithmic-bias/)
    *   **训练 (Training) 阶段:** 在模型训练过程中融入公平性考量。例如，训练AI模型时加入公平性约束，确保模型不会偏袒或歧视特定群体。[[ref]](https://tepperspectives.cmu.edu/all-articles/building-ai-fairness-by-reducing-algorithmic-bias/)[[ref]](https://www.tcs.com/what-we-do/products-platforms/tcs-bancs/articles/algorithmic-bias-ai-mitigation-strategies)
    *   **后训练 (Post-training) 阶段:** 对已训练模型的输出进行调整以纠正偏见。[[ref]](https://tepperspectives.cmu.edu/all-articles/building-ai-fairness-by-reducing-algorithmic-bias/)
*   **技术解决方案:**
    *   **差分隐私 (Differential Privacy, DP):** 通过向数据生成过程引入校准噪声来保护隐私。较低的隐私预算（ϵ）能提供更强的隐私保护，但可能牺牲数据实用性。研究显示，DP虽能增强隐私，但普遍降低合成数据的保真度和实用性，且并非总能显著降低隐私风险。[[ref]](https://www.frontiersin.org/journals/digital-health/articles/10.3389/fdgth.2025.1576290/full)
    *   **其他技术策略:** 包括数据加水印、通过区块链方法进行数字认证真实数据、开发AI工具检测伪造数据和图像，以及更广义的用于保护数据隐私、识别和改进算法及模型偏见的方法和程序。[[ref]](https://www.pnas.org/doi/10.1073/pnas.2409182122)
*   **综合管理措施:**
    *   **清晰定义与来源可靠性:** 建立合成数据的明确定义，区分其与真实数据，并通过强调“来源可靠性”来定义真实数据，以维护数据完整性。[[ref]](https://www.pnas.org/doi/10.1073/pnas.2409182122)
    *   **披露与透明度指南:** 制定使用合成数据的披露指南，要求科学家解释使用方式和原因，明确合成部分，并分享相关生成代码、算法和数据。[[ref]](https://www.pnas.org/doi/10.1073/pnas.2409182122)
    *   **教育与道德培训:** 将合成数据负责任使用的讨论纳入科学实践和方法学的教育和指导中，提高研究人员对伦理问题的认识。[[ref]](https://www.pnas.org/doi/10.1073/pnas.2409182122)

## 4. 结论

合成数据作为一种变革性技术，为解决传统数据应用的诸多挑战提供了新的路径。然而，其广泛且负责任的应用必须建立在对其质量进行科学评估以及对其潜在伦理风险进行严格管理的基础之上。在质量评估方面，通过保真度、多样性和实用性三大维度的多指标综合考量，可以全面量化合成数据与真实数据的一致性和有效性。DCScore等新兴指标为多样性评估提供了新视角，而TSTR/TRTR框架则直接量化了实用性。在伦理层面，合成数据存在继承和放大训练数据中固有偏见的风险，可能导致歧视、数据完整性受损和隐私泄露。为此，在数据生成、模型训练和后处理等各个阶段实施算法公平性策略至关重要，包括差分隐私等技术解决方案以及提升透明度、加强教育和建立明确指南等综合性措施。未来研究应持续完善评估框架，探索更高效的偏见缓解技术，并在实际应用中平衡好隐私、保真度和实用性之间的复杂权衡，以最大化合成数据带来的益处，同时将潜在危害降至最低。

## 5. 参考文献

1.  https://aws.amazon.com/blogs/machine-learning/how-to-evaluate-the-quality-of-the-synthetic-data-measuring-from-the-perspective-of-fidelity-utility-and-privacy/
2.  https://www.frontiersin.org/journals/digital-health/articles/10.3389/fdgth.2025.1576290/full
3.  https://www.pnas.org/doi/10.1073/pnas.2409182122
4.  https://www.sciencedirect.com/science/article/pii/S0167739X24000694
5.  https://arxiv.org/html/2502.08512v1
6.  https://pmc.ncbi.nlm.nih.gov/articles/PMC12778113/
7.  https://www.adalovelaceinstitute.org/blog/synthetic-data-real-harm/
8.  https://bluegen.ai/how-does-synthetic-data-generation-help-reduce-algorithmic-bias/
9.  https://tepperspectives.cmu.edu/all-articles/building-ai-fairness-by-reducing-algorithmic-bias/
10. https://www.tcs.com/what-we-do/products-platforms/tcs-bancs/articles/algorithmic-bias-ai-mitigation-strategies